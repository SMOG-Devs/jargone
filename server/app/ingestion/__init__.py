"""
Ingestion of documents in chunks to the vector database.

Steps: 
1. Split the document into chunks.
2. Generate embeddings for each chunk.
3. Store the embeddings in the vector database.

OpenAI API is used to generate the embeddings.In the final product on-premise LLM will be used to ensure the privacy of the data.
"""





